#!/usr/bin/env python
# -*- coding: latin-1 -*-

# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# Author: marmuta <marmvta@gmail.com>
#

import sys,math
import codecs
import re
import lm


def main():
    global model # for debugging
    
    model = LanguageModel()
    training, held_out, testing = model.read_corpus(sys.argv[1])

    model.set_order(int(sys.argv[2]))
    model.train(training)
    model.train(held_out)   # abuse held_out for now
    model.train(testing)    # abuse testing for now

    model.info()

    model.save(sys.argv[3])

class LanguageModel(lm.LanguageModelDynamic):

    def read_corpus(self, filename):
        # read corpus
        #s = codecs.open(filename, encoding='utf-8').read() \
        s = codecs.open(filename, encoding='latin-1').read() \
            .replace("\r"," ") # remove carriage returns from Moby Dick

        # split into sentences including separaters (punctuation, newlines)
        sentences = re.findall(""".*?(?:[\.;:!?][\s\"]  # punctuation
                                      | \s*\\n\s*\\n)   # double newline
                               """, s, re.UNICODE|re.DOTALL|re.VERBOSE)
        # divide corpus into 3 sections: training, held_out, test
        r = range(len(sentences))
        sh = set(r[5::20])
        st = set(r[15::20])
        training  = [sentences[i] for i in set(r) - sh - st]
        held_out  = [sentences[i] for i in sh]
        testing   = [sentences[i] for i in st]
        print "sentences: total %d, training %d, held_out %d, testing %d" % \
              (len(sentences),len(training),len(held_out),len(testing))

        return training, held_out, testing


    def info(self):
        counts = [0]*self.order
        totals = [0]*self.order
        for ng in self.iter_ngrams():
            counts[len(ng[0])-1] +=  1
            totals[len(ng[0])-1] += ng[1]
            
        for i,c in enumerate(counts):
            print "%d-grams: count %d, total %d" % \
                  (i+1, counts[i], totals[i])


    def train(self, sentences):
        """ extract and count n-grams """
        for sentence in sentences:
            words = self.split_sentence(sentence)
            for i,word in enumerate(words):
                for n in xrange(self.order):
                    if i+n+1 <= len(words):
                        assert(n == len(words[i:i+n+1])-1)
                        self.count_ngram(words[i:i+n+1])


    def split_sentence(self, sentence):
        words = re.findall(u"[^\W\d]\w*(?:[-'][\w]+)*",
                           sentence, re.UNICODE|re.VERBOSE)
        if words:
            words = [u"<s>"] + words + [u"<\s>"]
        return words


if __name__ == '__main__':
    main()

