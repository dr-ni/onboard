#!/usr/bin/python

# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# Author: marmuta <marmvta@gmail.com>
#

import os
import time

import gobject
import dbus
import dbus.service
import dbus.mainloop.glib

import pypredict
from pypredict import timeit

#-------------------------------------------------------------------------
# Config - gconf and configuration stuff
#-------------------------------------------------------------------------

import gconf
import sys
from optparse import OptionParser

INSTALL_DIR = "/usr/share/gpredict"

class Config (object):
    """
    Singleton Class to encapsulate the gconf stuff and check values.
    """

    _gconf_client = gconf.client_get_default()

    def __new__(cls, *args, **kwargs):
        """
        Singleton magic.
        """
        if not hasattr(cls, "self"):
            cls.self = object.__new__(cls)
            cls.self._init()
        return cls.self

    def _init(self):
        """
        Singleton constructor, should only run once.
        """
        parser = OptionParser()
        parser.add_option("-l", "--log", type="str", dest="log_level",
            help="LEVEL={notset|debug|info|warning|error|critical}")
        parser.add_option("-g", "--log-learning",
                  action="store_true", dest="log_learn", default=False,
                  help="log all learned text; off by default")
        options = parser.parse_args()[0]

        if options.log_level:
            logging.basicConfig(level=getattr(logging, options.log_level.upper()))
        else:
            logging.basicConfig()

        self.log_learn = options.log_learn

    def get_install_dir(self):
        # when installed
        if os.path.isdir(INSTALL_DIR):
            return INSTALL_DIR

        # assume running from the source directory
        return os.path.dirname(os.path.abspath(__file__))


#-------------------------------------------------------------------------
# WordPredictor - dbus object
#-------------------------------------------------------------------------

class DemoException(dbus.DBusException):
    _dbus_error_name = 'org.gnome.DemoException'

class WordPredictor(dbus.service.Object):

    @dbus.service.method("org.gnome.PredictionInterface",
                         in_signature='assi', out_signature='as')
    def predict(self, lmdesc, context_line, limit):
        context = pypredict.tokenize_context(context_line)
        model = self.get_prediction_model(lmdesc)
        with timeit("predict"):
            choices = model.predictp(context, limit)
        _logger.info("context=" + repr(context))
        _logger.info("choices=" + repr(choices[:5]))
        return [x[0] for x in choices]

    @dbus.service.method("org.gnome.PredictionInterface",
                         in_signature='assi', out_signature='a(sd)')
    def predictp(self, lmdesc, context_line, limit):
        context = pypredict.tokenize_context(context_line)
        model = self.get_prediction_model(lmdesc)
        with timeit("predict"):
            choices = model.predictp(context, limit)
        _logger.info("context=" + repr(context))
        _logger.info("choices=" + repr(choices[:5]))
        return choices

    @dbus.service.method("org.gnome.PredictionInterface",
                         in_signature='assb', out_signature='as')
    def learn_text(self, lmids, text, allow_new_words):
        tokens = pypredict.tokenize_text(text)
        for lmid in lmids:
            model = get_model(lmid)
            model.learn_tokens(tokens, allow_new_words)
            model.modified = True
        _logger.info("learn_text: tokens=" + repr(tokens[:10]))

        # debug: save all learned text for later optimization testing
        if config.log_learn:
            fn = "%s/.gpredict/learned_text.txt" % os.path.expanduser("~")
            with open(fn, "a") as f:
                f.write(text + "\n")

        return tokens

    @dbus.service.method("org.gnome.PredictionInterface",
                         in_signature='s', out_signature='as')
    def tokenize_text(self, text):
        tokens = pypredict.tokenize_text(text)
        _logger.info("tokenize_text: tokens=" + repr(tokens[:10]))
        return tokens

    @dbus.service.method("org.gnome.PredictionInterface",
                         in_signature='s', out_signature='as')
    def tokenize_context(self, text):
        tokens = pypredict.tokenize_context(text)
        _logger.info("tokenize_context: tokens=" + repr(tokens[:10]))
        return tokens

    @dbus.service.method("org.gnome.PredictionInterface",
                         in_signature='', out_signature='')
    def RaiseException(self):
        raise DemoException('The RaiseException method does what you might '
                            'expect')

    @dbus.service.method("org.gnome.PredictionInterface",
                         in_signature='', out_signature='')
    def Exit(self):
        _logger.info("exiting")
        mainloop.quit()

    def get_prediction_model(self, lmdesc):
        lmids, weights = parse_lmdesc(lmdesc)
        models = get_models(lmids)
        model = pypredict.overlay(models)
        #model = pypredict.linint(models, weights)
        #model = pypredict.loglinint(models, weights)
        return model


#-------------------------------------------------------------------------
# language model handling
#-------------------------------------------------------------------------

def get_models(lmids):
    models = []
    for lmid in lmids:
        model = get_model(lmid)
        if model:
            models.append(model)
    return models

def get_model(lmid):
    """ get language model from cache or load it from disk"""
    lmid = canonicalize_lmid(lmid)
    if lmid in language_models:
        model = language_models[lmid]
    else:
        model = load_model(lmid)
        if model:
            language_models[lmid] = model
    return model

def parse_lmdesc(lmdesc):
    """
        extract language model ids and interpolation weights from
        the language model description.
    """
    lmids = []
    weights = []

    for entry in lmdesc:
        fields = entry.split(",")

        lmids.append(fields[0])

        weight = 1.0
        if len(fields) >= 2: # weight is optional
            try:
                weight = float(fields[1])
            except:
                pass
        weights.append(weight)

    return lmids, weights

def canonicalize_lmid(lmid):
    """
        Fully qualifies and unifies language model ids.
        Fills in missing fields with default values.
        The result is of the format "type:class:name".
    """
    # default values
    result = ["lm", "system", "en"]
    for i, field in enumerate(lmid.split(":")[:3]):
        result[i] = field
    return ":".join(result)

def load_model(lmid):
    type_, class_, name  = lmid.split(":")

    if type_ == "lm":
        model = pypredict.DynamicModel()
        #model.smoothing = "kneser-ney"
        #model.smoothing = "abs-disc"
    elif type_ == "cache":
        model = pypredict.CacheModel()

    filename = get_filename(lmid)
    _logger.info("loading %s" % filename)
    try:
        model.load(filename)
    except IOError, e:
        _logger.warning("Failed to load language model '%s': %s (%d)" %
                        (filename, os.strerror(e.errno), e.errno))
    model.modified = False
    return model

def save_models():
    for lmid,model in language_models.items():
        if can_save(lmid):
            save_model(model, lmid)

def can_save(lmid):
    type_, class_, name  = lmid.split(":")
    return class_ == "user"
    
def save_model(model, lmid):
    type_, class_, name  = lmid.split(":")
    filename = get_filename(lmid)

    if model.modified or \
       not os.path.exists(filename):
        _logger.info("saving language model '%s'" % filename)

        try:
            # create the path
            path = os.path.dirname(filename)
            if not os.path.exists(path):
                os.makedirs(path)

            # save to temp file
            basename, ext = os.path.splitext(filename)
            tempfile = basename + ".tmp"
            model.save(tempfile)

            # rename to final file
            if os.path.exists(filename):
                os.rename(filename, filename + ".bak")
            os.rename(tempfile, filename)

            model.modified = False
        except (IOError, OSError), e:
            _logger.warning("Failed to save language model '%s': %s (%d)" %
                            (filename, os.strerror(e.errno), e.errno))

def get_filename(lmid):
    type_, class_, name  = lmid.split(":")
    if class_ == "system":
        path = os.path.join(config.get_install_dir(), "models")
    else: # class_ == "user":
        path = "%s/.gpredict/models" \
                              % os.path.expanduser("~")
    ext = type_
    return os.path.join(path, name + "." + ext)


#-------------------------------------------------------------------------
# auto save timer
#-------------------------------------------------------------------------

auto_save_interval = 10 * 60  # in seconds, 0=off
last_auto_save_time = 0

def auto_save_callback():
    global last_auto_save_time

    if auto_save_interval:   # 0=no auto save
        t = time.time()
        if t - last_auto_save_time > auto_save_interval:
            last_auto_save_time = t
            save_models()
    return True # run again

#-------------------------------------------------------------------------
# main
#-------------------------------------------------------------------------

### Logging ###
import logging
_logger = logging.getLogger("gpredict")
###############

### Config Singleton ###
config = Config()
########################


if __name__ == '__main__':

    _logger.setLevel(logging.DEBUG)
    _logger.info("gpredict D-bus service")

    # cache of language models
    language_models = {}

    # D-Bus init
    dbus.mainloop.glib.DBusGMainLoop(set_as_default=True)
    session_bus = dbus.SessionBus()
    name = dbus.service.BusName("org.gnome.PredictionService", session_bus)
    object = WordPredictor(session_bus, '/WordPredictor')

    # setup auto save timer
    auto_save_timer = gobject.timeout_add_seconds(5, auto_save_callback)

    # testing
    # Stopping into the debugger while in a D-Bus call locks up all gnome apps,
    # so do the debugging here. Temporariliy change the bus name above to really
    # stop all clients from meddling.
    if 0:
        choices = object.predictp(["lm:system:en",
                                   "lm:user:en",
                                   "cache:user:default"
                                  ], u"Moby ", 10)
    #    model = object.get_model('en:user:lm')
    #    model.count_ngram([u"Moby", u"Duck"])
        object.learn_text(["lm:user:en",
                            "cache:user:default",
                          ], u"Moby Duck the whale", True)
        model = get_model("lm:user:en")
        for ng in model.iter_ngrams():
            print ng
        choices = object.predictp(["lm:system:en",
                                   "lm:user:en",
                                   "cache:user:default",
                                  ], u"Moby ", 10)

        models = [get_model("lm:system:en"),
                  get_model("lm:user:en")]
        print "overlay:   ", pypredict.overlay(models).predictp([u"Moby", u""], 10)
        print "linint:    ", pypredict.linint(models).predictp([u"Moby", u""], 10)
        print "loglinint: ", pypredict.loglinint(models).predictp([u"Moby", u""], 10)

    # main loop
    _logger.info("waiting for clients")
    mainloop = gobject.MainLoop()
    try:
        mainloop.run()
    except KeyboardInterrupt:
        pass

    # exit
    gobject.source_remove(auto_save_timer)
    save_models()

